{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sAwFPnpsiQVx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from pathlib import Path  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRZ_njaCil5L"
      },
      "source": [
        "#1. Qatar Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yvOcpRqvicVo"
      },
      "outputs": [],
      "source": [
        "def scrape_page_QA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/qatar-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahMABFjyiiLe",
        "outputId": "f920d41d-89e9-41db-fa72-a792db311737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n",
            "250 pages extraction completed\n",
            "260 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "# Main loop to scrape multiple pages and track progress\n",
        "qatar_airways_reviews = []\n",
        "total_pages = 264\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_QA(page_number)\n",
        "    qatar_airways_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8y6cUoG3i6Fx"
      },
      "outputs": [],
      "source": [
        "qatar_airways_reviews_df = pd.DataFrame(qatar_airways_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "cHHyMFAcilAG",
        "outputId": "9ce10914-cdf4-4e55-f84f-21e7d22638f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>Anders Pedersen</td>\n",
              "      <td>2021-08-23</td>\n",
              "      <td>✅ Trip Verified | Award ticket from KGL to CPH...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>Michael Schade</td>\n",
              "      <td>2023-01-15</td>\n",
              "      <td>✅ Trip Verified | Check-in and security check ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>Mingxiu Huang</td>\n",
              "      <td>2016-02-07</td>\n",
              "      <td>Singapore to Paris via Doha, and Qatar Airways...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2306</th>\n",
              "      <td>M Khan</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>Manchester-Doha sector.–While boarding had to ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>Michael Schade</td>\n",
              "      <td>2023-07-26</td>\n",
              "      <td>✅ Trip Verified | -I was informed three month ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Name Date Published  \\\n",
              "816   Anders Pedersen     2021-08-23   \n",
              "508    Michael Schade     2023-01-15   \n",
              "1971    Mingxiu Huang     2016-02-07   \n",
              "2306           M Khan     2015-01-19   \n",
              "401    Michael Schade     2023-07-26   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "816   ✅ Trip Verified | Award ticket from KGL to CPH...      9  \n",
              "508   ✅ Trip Verified | Check-in and security check ...      8  \n",
              "1971  Singapore to Paris via Doha, and Qatar Airways...      4  \n",
              "2306  Manchester-Doha sector.–While boarding had to ...      8  \n",
              "401   ✅ Trip Verified | -I was informed three month ...      3  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qatar_airways_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMP8_ebVi-9g",
        "outputId": "3effdc08-72a7-4f20-aa39-7b5df67acf86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2638, 4)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qatar_airways_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6xbnT3jB7s"
      },
      "source": [
        "#2. Singapore Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cqrlofMejFhI"
      },
      "outputs": [],
      "source": [
        "def scrape_page_SQ(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/singapore-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szse68FujRI3",
        "outputId": "0cb6cd4d-d0a5-4dfd-8b50-65602f625666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "singapore_airlines_reviews = []\n",
        "total_pages = 167\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_SQ(page_number)\n",
        "    singapore_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5gAEbZcEjRAP"
      },
      "outputs": [],
      "source": [
        "singapore_airlines_reviews_df = pd.DataFrame(singapore_airlines_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "DDpANboqjQ8X",
        "outputId": "50058bcf-3bdf-4f64-e810-cc99577451a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>W Khan</td>\n",
              "      <td>2017-09-16</td>\n",
              "      <td>✅ Verified Review |  Dhaka to Singapore in eco...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>W Teale</td>\n",
              "      <td>2020-01-26</td>\n",
              "      <td>✅ Trip Verified |  Upon attempting to return t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Steve Siauw</td>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>✅ Verified Review |  Tokyo to Jakarta via Sing...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>G Paulson</td>\n",
              "      <td>2018-08-31</td>\n",
              "      <td>✅ Trip Verified | Singapore to Hong Kong. New ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>W Manarlo</td>\n",
              "      <td>2020-03-07</td>\n",
              "      <td>✅ Trip Verified |  Makassar to Singapore. It t...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Name Date Published  \\\n",
              "876       W Khan     2017-09-16   \n",
              "448      W Teale     2020-01-26   \n",
              "995  Steve Siauw     2016-12-30   \n",
              "736    G Paulson     2018-08-31   \n",
              "425    W Manarlo     2020-03-07   \n",
              "\n",
              "                                          Text Content Rating  \n",
              "876  ✅ Verified Review |  Dhaka to Singapore in eco...     10  \n",
              "448  ✅ Trip Verified |  Upon attempting to return t...      1  \n",
              "995  ✅ Verified Review |  Tokyo to Jakarta via Sing...      6  \n",
              "736  ✅ Trip Verified | Singapore to Hong Kong. New ...      4  \n",
              "425  ✅ Trip Verified |  Makassar to Singapore. It t...      8  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "singapore_airlines_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtyyXFWFjQ3R",
        "outputId": "9e66b70a-ae9e-4f59-e39d-e83e887e02a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1670, 4)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "singapore_airlines_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbUxcX03ky91"
      },
      "source": [
        "#3. Cathay Pacific Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IR3N2HFnjQu4"
      },
      "outputs": [],
      "source": [
        "def scrape_page_CP(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/cathay-pacific-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aUMU1iYlKF8",
        "outputId": "f4233597-a574-49cc-bcc1-15b6914e9d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews = []\n",
        "total_pages = 151\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_CP(page_number)\n",
        "    cathay_pacific_airways_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f3VU9zRelXUv"
      },
      "outputs": [],
      "source": [
        "cathay_pacific_airways_reviews_df = pd.DataFrame(cathay_pacific_airways_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "LUZ79htGlibL",
        "outputId": "5ba0f0ee-9163-468f-f008-5981ce6c8f71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>J Chen</td>\n",
              "      <td>2018-06-03</td>\n",
              "      <td>✅ Trip Verified |  Manila to Hong Kong. Cathay...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Philippe Gimenez</td>\n",
              "      <td>2024-12-01</td>\n",
              "      <td>✅ Trip Verified |   I'm deeply upset about the...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>Alison Chambers</td>\n",
              "      <td>2015-10-15</td>\n",
              "      <td>The food on Cathay Pacific Airways was truly a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>Charles Hamilton</td>\n",
              "      <td>2013-10-02</td>\n",
              "      <td>I flew business from LHR to HKG and HKG to Mel...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>C Owen</td>\n",
              "      <td>2019-11-11</td>\n",
              "      <td>Not Verified |  London to Manila via Hong Kong...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Name Date Published  \\\n",
              "462             J Chen     2018-06-03   \n",
              "45    Philippe Gimenez     2024-12-01   \n",
              "969    Alison Chambers     2015-10-15   \n",
              "1472  Charles Hamilton     2013-10-02   \n",
              "230             C Owen     2019-11-11   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "462   ✅ Trip Verified |  Manila to Hong Kong. Cathay...      5  \n",
              "45    ✅ Trip Verified |   I'm deeply upset about the...      2  \n",
              "969   The food on Cathay Pacific Airways was truly a...      3  \n",
              "1472  I flew business from LHR to HKG and HKG to Mel...      8  \n",
              "230   Not Verified |  London to Manila via Hong Kong...     10  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1LQ8zOFllYT",
        "outputId": "ff2d387e-53a4-4c20-cbf8-dc179ab9742f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1508, 4)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8ZOCs0jlptQ"
      },
      "source": [
        "#4. Emirates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JQJWSfO2lwiK"
      },
      "outputs": [],
      "source": [
        "def scrape_page_EM(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/emirates/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJGDlaQZl5yS",
        "outputId": "d6177293-45c7-46be-fe33-36a1b79a4389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "emirates_reviews = []\n",
        "total_pages = 247\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_EM(page_number)\n",
        "    emirates_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Wy0X4gQTm0xk"
      },
      "outputs": [],
      "source": [
        "emirates_reviews_df = pd.DataFrame(emirates_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "-a50r8iUm5bI",
        "outputId": "42a9f28d-04b6-4d3c-d62b-403d40a1bb09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>Rajah Koppala</td>\n",
              "      <td>2018-04-23</td>\n",
              "      <td>✅ Trip Verified |  Hyderabad to New York via D...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>T Keen</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>✅ Trip Verified |  I’ve flown Emirates a few t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>A Jones</td>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>LHR-DXB-BKK / BKK-DXB-LHR. My first experience...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>Advay Biswal</td>\n",
              "      <td>2023-01-23</td>\n",
              "      <td>✅ Trip Verified | The airline was very good. T...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>K Hazil</td>\n",
              "      <td>2016-10-19</td>\n",
              "      <td>✅ Verified Review |  Washington to Dubai. I ar...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Name Date Published  \\\n",
              "953   Rajah Koppala     2018-04-23   \n",
              "100          T Keen     2024-05-07   \n",
              "2106        A Jones     2014-09-17   \n",
              "249    Advay Biswal     2023-01-23   \n",
              "1364        K Hazil     2016-10-19   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "953   ✅ Trip Verified |  Hyderabad to New York via D...      3  \n",
              "100   ✅ Trip Verified |  I’ve flown Emirates a few t...      2  \n",
              "2106  LHR-DXB-BKK / BKK-DXB-LHR. My first experience...     10  \n",
              "249   ✅ Trip Verified | The airline was very good. T...     10  \n",
              "1364  ✅ Verified Review |  Washington to Dubai. I ar...      8  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emirates_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccCNXlTm7mw",
        "outputId": "ddac4cae-2c63-48bd-8fc2-256c6dd5b778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2464, 4)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emirates_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EsysrJm-_M"
      },
      "source": [
        "#5.ANA All Nippon Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RJ6d3EuFnFMg"
      },
      "outputs": [],
      "source": [
        "def scrape_page_ANA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/ana-all-nippon-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KgCU31snNaA",
        "outputId": "cc115d47-b643-4cee-f990-c0829ff6c367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "ANA_reviews = []\n",
        "total_pages = 62\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_ANA(page_number)\n",
        "    ANA_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n2QcSkg-naGj"
      },
      "outputs": [],
      "source": [
        "ANA_reviews_df = pd.DataFrame(ANA_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "lk9_YTSSny-G",
        "outputId": "1b20ed61-4a3c-48bb-f70f-d888ed89b174"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>G Brambilla</td>\n",
              "      <td>2015-06-06</td>\n",
              "      <td>HND - OKA economy 24 May 2015 NH479. The fligh...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>L Andres</td>\n",
              "      <td>2013-01-30</td>\n",
              "      <td>Took ANA from SEA-NRT-MNL and back. Flight fro...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Ronny Adriansyah</td>\n",
              "      <td>2021-02-05</td>\n",
              "      <td>✅ Trip Verified | Flew ANA Tokyo Narita - Jaka...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>A Moon</td>\n",
              "      <td>2010-06-10</td>\n",
              "      <td>ANA failed to alert passengers about its cance...</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>S Vana</td>\n",
              "      <td>2018-06-21</td>\n",
              "      <td>✅ Trip Verified |  Our flight from Hiroshima t...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Name Date Published  \\\n",
              "360       G Brambilla     2015-06-06   \n",
              "510          L Andres     2013-01-30   \n",
              "100  Ronny Adriansyah     2021-02-05   \n",
              "599            A Moon     2010-06-10   \n",
              "180            S Vana     2018-06-21   \n",
              "\n",
              "                                          Text Content Rating  \n",
              "360  HND - OKA economy 24 May 2015 NH479. The fligh...      5  \n",
              "510  Took ANA from SEA-NRT-MNL and back. Flight fro...      5  \n",
              "100  ✅ Trip Verified | Flew ANA Tokyo Narita - Jaka...      8  \n",
              "599  ANA failed to alert passengers about its cance...    N/A  \n",
              "180  ✅ Trip Verified |  Our flight from Hiroshima t...     10  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANA_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtM_sBhn1Kf",
        "outputId": "03faef89-8ada-42fb-dfd6-e3ed54bdfcff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(620, 4)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANA_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDr4aW8an5CZ"
      },
      "source": [
        "#6. Turkish Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "X-RbwaSJn-wN"
      },
      "outputs": [],
      "source": [
        "def scrape_page_Turk(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/turkish-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qytC_yfqoYDF",
        "outputId": "52ef200d-e2d0-4ee2-d7e0-f9727aa4cb66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n",
            "250 pages extraction completed\n",
            "260 pages extraction completed\n",
            "270 pages extraction completed\n",
            "280 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "turkish_airlines_reviews = []\n",
        "total_pages = 280\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_Turk(page_number)\n",
        "    turkish_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "azbkUuDvpZ1i"
      },
      "outputs": [],
      "source": [
        "turkish_airlines_reviews_df = pd.DataFrame(turkish_airlines_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "bJfb11e2pbOI",
        "outputId": "401d274e-58fc-4a85-af41-67d69cf3109f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2372</th>\n",
              "      <td>S Northcote</td>\n",
              "      <td>2015-04-24</td>\n",
              "      <td>First time travelling with Turkish Airlines I ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1352</th>\n",
              "      <td>Jim Burt</td>\n",
              "      <td>2019-03-14</td>\n",
              "      <td>Not Verified |  New York to Tel Aviv via Istan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2777</th>\n",
              "      <td>T Foran</td>\n",
              "      <td>2013-10-07</td>\n",
              "      <td>YYZ-IST-YYZ. Turkish is inconsistent. Business...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>S Maris</td>\n",
              "      <td>2023-04-10</td>\n",
              "      <td>✅ Trip Verified | After booking and paying ext...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>P Engle</td>\n",
              "      <td>2022-06-13</td>\n",
              "      <td>✅ Trip Verified | San Francisco to Tehran via ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Name Date Published  \\\n",
              "2372  S Northcote     2015-04-24   \n",
              "1352     Jim Burt     2019-03-14   \n",
              "2777      T Foran     2013-10-07   \n",
              "516       S Maris     2023-04-10   \n",
              "663       P Engle     2022-06-13   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "2372  First time travelling with Turkish Airlines I ...      2  \n",
              "1352  Not Verified |  New York to Tel Aviv via Istan...      1  \n",
              "2777  YYZ-IST-YYZ. Turkish is inconsistent. Business...      7  \n",
              "516   ✅ Trip Verified | After booking and paying ext...      1  \n",
              "663   ✅ Trip Verified | San Francisco to Tehran via ...      1  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turkish_airlines_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVPkCPfopc1m",
        "outputId": "508f0749-61c6-4c71-a81f-92ecdd98803a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2800, 4)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turkish_airlines_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#7. Korean Air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_KA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/korean-air/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "korean_air_reviews = []\n",
        "total_pages = 60\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_KA(page_number)\n",
        "    korean_air_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "korean_air_reviews_df = pd.DataFrame(korean_air_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#8. Air France"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_AF(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/air-france/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "air_france_reviews = []\n",
        "total_pages = 146\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_AF(page_number)\n",
        "    air_france_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "air_france_reviews_df = pd.DataFrame(air_france_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#9. Japan Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_JA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/japan-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "japan_airlines_reviews = []\n",
        "total_pages = 44\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_JA(page_number)\n",
        "    japan_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "japan_airlines_reviews_df = pd.DataFrame(japan_airlines_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#10. Hainan Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_HA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/hainan-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "hainan_airlines_reviews = []\n",
        "total_pages = 43\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_HA(page_number)\n",
        "    hainan_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "hainan_airlines_reviews_df = pd.DataFrame(hainan_airlines_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining Datasets together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uHiVTVI3rTKe"
      },
      "outputs": [],
      "source": [
        "qatar_airways_reviews_df.insert(0, 'Airlines', 'qatar_airways')\n",
        "singapore_airlines_reviews_df.insert(0, 'Airlines', 'singapore_airlines')\n",
        "cathay_pacific_airways_reviews_df.insert(0, 'Airlines', 'cathay_pacific_airlines')\n",
        "emirates_reviews_df.insert(0, 'Airlines', 'emirates')\n",
        "ANA_reviews_df.insert(0, 'Airlines', 'all_nippon_airways')\n",
        "turkish_airlines_reviews_df.insert(0, 'Airlines', 'turkish_airlines')\n",
        "korean_air_reviews_df.insert(0, 'Airlines', 'korean_air')\n",
        "air_france_reviews_df.insert(0, 'Airlines', 'air_france')\n",
        "japan_airlines_reviews_df.insert(0, 'Airlines', 'japan_airlines')\n",
        "hainan_airlines_reviews_df.insert(0, 'Airlines', 'hainan_airlines')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uOPCjB3rriRa"
      },
      "outputs": [],
      "source": [
        "airlines_review = pd.concat([\n",
        "    qatar_airways_reviews_df,\n",
        "    singapore_airlines_reviews_df,\n",
        "    cathay_pacific_airways_reviews_df,\n",
        "    emirates_reviews_df,\n",
        "    ANA_reviews_df,\n",
        "    turkish_airlines_reviews_df,\n",
        "    korean_air_reviews_df,\n",
        "    air_france_reviews_df,\n",
        "    japan_airlines_reviews_df,\n",
        "    hainan_airlines_reviews_df\n",
        "], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VcJufYJCsC3x",
        "outputId": "b4b69043-d76e-4268-cb64-414a697c0379"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airlines</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13801</th>\n",
              "      <td>japan_airlines</td>\n",
              "      <td>D Smith</td>\n",
              "      <td>2022-10-24</td>\n",
              "      <td>Not Verified |  New business class Suite III i...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>Naeem Alzidi</td>\n",
              "      <td>2022-04-21</td>\n",
              "      <td>✅ Trip Verified |  The service was good and th...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>G Stanagoulis</td>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>✅ Trip Verified |  Doha to Athens in January 2...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10037</th>\n",
              "      <td>turkish_airlines</td>\n",
              "      <td>Bih Luh Hew</td>\n",
              "      <td>2019-12-09</td>\n",
              "      <td>✅ Trip Verified |  Istanbul to Kuala Lumpur. B...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>Natalja Litvinova</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>✅ Trip Verified |  Absolutely memorable trip, ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13373</th>\n",
              "      <td>air_france</td>\n",
              "      <td>S Siauw</td>\n",
              "      <td>2015-06-25</td>\n",
              "      <td>A320 short haul London to Paris. Professional ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>Tercon Bojan</td>\n",
              "      <td>2014-11-11</td>\n",
              "      <td>Finally I get to fly on the Dreamliner! And Qa...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2433</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>A Cianetti</td>\n",
              "      <td>2014-06-23</td>\n",
              "      <td>FCO-DOH-BKK and vice versa. Finally a new hub ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5821</th>\n",
              "      <td>emirates</td>\n",
              "      <td>Val Marques</td>\n",
              "      <td>2025-09-02</td>\n",
              "      <td>✅ Trip Verified |   The flight was good, no pr...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13728</th>\n",
              "      <td>air_france</td>\n",
              "      <td>Emmanuel Cuignet</td>\n",
              "      <td>2013-07-22</td>\n",
              "      <td>CDG (2F) - NCE. The flight was in a newly refu...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Airlines               Name Date Published  \\\n",
              "13801    japan_airlines            D Smith     2022-10-24   \n",
              "702       qatar_airways       Naeem Alzidi     2022-04-21   \n",
              "1485      qatar_airways      G Stanagoulis     2018-01-02   \n",
              "10037  turkish_airlines        Bih Luh Hew     2019-12-09   \n",
              "397       qatar_airways  Natalja Litvinova     2023-08-01   \n",
              "13373        air_france            S Siauw     2015-06-25   \n",
              "2349      qatar_airways       Tercon Bojan     2014-11-11   \n",
              "2433      qatar_airways         A Cianetti     2014-06-23   \n",
              "5821           emirates        Val Marques     2025-09-02   \n",
              "13728        air_france   Emmanuel Cuignet     2013-07-22   \n",
              "\n",
              "                                            Text Content Rating  \n",
              "13801  Not Verified |  New business class Suite III i...      5  \n",
              "702    ✅ Trip Verified |  The service was good and th...     10  \n",
              "1485   ✅ Trip Verified |  Doha to Athens in January 2...      9  \n",
              "10037  ✅ Trip Verified |  Istanbul to Kuala Lumpur. B...      3  \n",
              "397    ✅ Trip Verified |  Absolutely memorable trip, ...     10  \n",
              "13373  A320 short haul London to Paris. Professional ...      8  \n",
              "2349   Finally I get to fly on the Dreamliner! And Qa...     10  \n",
              "2433   FCO-DOH-BKK and vice versa. Finally a new hub ...      3  \n",
              "5821   ✅ Trip Verified |   The flight was good, no pr...      3  \n",
              "13728  CDG (2F) - NCE. The flight was in a newly refu...      8  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airlines_review.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lwqQtCzsFjJ",
        "outputId": "4dc577a6-fa92-4b94-e868-3bf249f9f91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14602, 5)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airlines_review.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sYBW_lnsOAA"
      },
      "outputs": [],
      "source": [
        "airlines_review.to_csv('data/airlines_review.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
