{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sAwFPnpsiQVx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from pathlib import Path  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRZ_njaCil5L"
      },
      "source": [
        "#1. Qatar Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yvOcpRqvicVo"
      },
      "outputs": [],
      "source": [
        "def scrape_page_QA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/qatar-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahMABFjyiiLe",
        "outputId": "f920d41d-89e9-41db-fa72-a792db311737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n",
            "250 pages extraction completed\n",
            "260 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "# Main loop to scrape multiple pages and track progress\n",
        "qatar_airways_reviews = []\n",
        "total_pages = 264\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_QA(page_number)\n",
        "    qatar_airways_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8y6cUoG3i6Fx"
      },
      "outputs": [],
      "source": [
        "qatar_airways_reviews_df = pd.DataFrame(qatar_airways_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "cHHyMFAcilAG",
        "outputId": "9ce10914-cdf4-4e55-f84f-21e7d22638f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>Naeem Alzidi</td>\n",
              "      <td>2022-04-21</td>\n",
              "      <td>✅ Trip Verified |  The service was good and th...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1564</th>\n",
              "      <td>Anders Pedersen</td>\n",
              "      <td>2017-10-03</td>\n",
              "      <td>✅ Verified Review |  Copenhagen to Ho Chi Minh...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1927</th>\n",
              "      <td>Patricia McGurk</td>\n",
              "      <td>2016-04-08</td>\n",
              "      <td>✅ Verified Review |  We were due to travel fro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2306</th>\n",
              "      <td>M Khan</td>\n",
              "      <td>2015-01-19</td>\n",
              "      <td>Manchester-Doha sector.–While boarding had to ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2114</th>\n",
              "      <td>Sally Hirshfield</td>\n",
              "      <td>2015-09-04</td>\n",
              "      <td>This was the second leg of a flight from Madri...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Name Date Published  \\\n",
              "702       Naeem Alzidi     2022-04-21   \n",
              "1564   Anders Pedersen     2017-10-03   \n",
              "1927   Patricia McGurk     2016-04-08   \n",
              "2306            M Khan     2015-01-19   \n",
              "2114  Sally Hirshfield     2015-09-04   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "702   ✅ Trip Verified |  The service was good and th...     10  \n",
              "1564  ✅ Verified Review |  Copenhagen to Ho Chi Minh...      8  \n",
              "1927  ✅ Verified Review |  We were due to travel fro...      2  \n",
              "2306  Manchester-Doha sector.–While boarding had to ...      8  \n",
              "2114  This was the second leg of a flight from Madri...     10  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qatar_airways_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMP8_ebVi-9g",
        "outputId": "3effdc08-72a7-4f20-aa39-7b5df67acf86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2638, 4)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qatar_airways_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6xbnT3jB7s"
      },
      "source": [
        "#2. Singapore Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cqrlofMejFhI"
      },
      "outputs": [],
      "source": [
        "def scrape_page_SQ(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/singapore-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szse68FujRI3",
        "outputId": "0cb6cd4d-d0a5-4dfd-8b50-65602f625666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "singapore_airlines_reviews = []\n",
        "total_pages = 167\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_SQ(page_number)\n",
        "    singapore_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5gAEbZcEjRAP"
      },
      "outputs": [],
      "source": [
        "singapore_airlines_reviews_df = pd.DataFrame(singapore_airlines_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "DDpANboqjQ8X",
        "outputId": "50058bcf-3bdf-4f64-e810-cc99577451a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>I Lamakatan</td>\n",
              "      <td>2017-06-30</td>\n",
              "      <td>✅ Verified Review |  Singapore to Beijing, fli...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>Azri Azmi</td>\n",
              "      <td>2015-10-06</td>\n",
              "      <td>I flew Singapore Airlines Boeing 777 from Sing...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>P Rachitra</td>\n",
              "      <td>2019-02-27</td>\n",
              "      <td>✅ Trip Verified |  San Francisco to Bangalore ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>R Martashan</td>\n",
              "      <td>2022-04-05</td>\n",
              "      <td>✅ Trip Verified |  Flew today 5th April 2022 o...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>Krish Mohan</td>\n",
              "      <td>2014-12-10</td>\n",
              "      <td>SQ 15 - Sep 29. SQ402 - Oct 1. SQ5357 Oct 24. ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Name Date Published  \\\n",
              "906   I Lamakatan     2017-06-30   \n",
              "1209    Azri Azmi     2015-10-06   \n",
              "645    P Rachitra     2019-02-27   \n",
              "369   R Martashan     2022-04-05   \n",
              "1350  Krish Mohan     2014-12-10   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "906   ✅ Verified Review |  Singapore to Beijing, fli...      9  \n",
              "1209  I flew Singapore Airlines Boeing 777 from Sing...      6  \n",
              "645   ✅ Trip Verified |  San Francisco to Bangalore ...      3  \n",
              "369   ✅ Trip Verified |  Flew today 5th April 2022 o...     10  \n",
              "1350  SQ 15 - Sep 29. SQ402 - Oct 1. SQ5357 Oct 24. ...      9  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "singapore_airlines_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtyyXFWFjQ3R",
        "outputId": "9e66b70a-ae9e-4f59-e39d-e83e887e02a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1670, 4)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "singapore_airlines_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbUxcX03ky91"
      },
      "source": [
        "#3. Cathay Pacific Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "IR3N2HFnjQu4"
      },
      "outputs": [],
      "source": [
        "def scrape_page_CP(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/cathay-pacific-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aUMU1iYlKF8",
        "outputId": "f4233597-a574-49cc-bcc1-15b6914e9d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews = []\n",
        "total_pages = 151\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_CP(page_number)\n",
        "    cathay_pacific_airways_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "f3VU9zRelXUv"
      },
      "outputs": [],
      "source": [
        "cathay_pacific_airways_reviews_df = pd.DataFrame(cathay_pacific_airways_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "LUZ79htGlibL",
        "outputId": "5ba0f0ee-9163-468f-f008-5981ce6c8f71"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>Francis Wong</td>\n",
              "      <td>2023-03-30</td>\n",
              "      <td>✅ Trip Verified | After almost 8 years of not ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>Jennifer Bentley</td>\n",
              "      <td>2015-10-30</td>\n",
              "      <td>London to Auckland via Hong Kong. Excellent se...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>W Patavik</td>\n",
              "      <td>2017-05-19</td>\n",
              "      <td>✅ Verified Review |  Vancouver to Bangkok via ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Joash Fang</td>\n",
              "      <td>2023-02-13</td>\n",
              "      <td>✅ Trip Verified |  Cathay Pacific's Premium Ec...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>Melanie Pemberton</td>\n",
              "      <td>2016-10-23</td>\n",
              "      <td>✅ Verified Review |  Manchester to Sydney via ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Name Date Published  \\\n",
              "124       Francis Wong     2023-03-30   \n",
              "962   Jennifer Bentley     2015-10-30   \n",
              "650          W Patavik     2017-05-19   \n",
              "142         Joash Fang     2023-02-13   \n",
              "741  Melanie Pemberton     2016-10-23   \n",
              "\n",
              "                                          Text Content Rating  \n",
              "124  ✅ Trip Verified | After almost 8 years of not ...      8  \n",
              "962  London to Auckland via Hong Kong. Excellent se...      9  \n",
              "650  ✅ Verified Review |  Vancouver to Bangkok via ...     10  \n",
              "142  ✅ Trip Verified |  Cathay Pacific's Premium Ec...      5  \n",
              "741  ✅ Verified Review |  Manchester to Sydney via ...      9  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1LQ8zOFllYT",
        "outputId": "ff2d387e-53a4-4c20-cbf8-dc179ab9742f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1508, 4)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cathay_pacific_airways_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8ZOCs0jlptQ"
      },
      "source": [
        "#4. Emirates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JQJWSfO2lwiK"
      },
      "outputs": [],
      "source": [
        "def scrape_page_EM(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/emirates/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJGDlaQZl5yS",
        "outputId": "d6177293-45c7-46be-fe33-36a1b79a4389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "emirates_reviews = []\n",
        "total_pages = 247\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_EM(page_number)\n",
        "    emirates_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Wy0X4gQTm0xk"
      },
      "outputs": [],
      "source": [
        "emirates_reviews_df = pd.DataFrame(emirates_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "-a50r8iUm5bI",
        "outputId": "42a9f28d-04b6-4d3c-d62b-403d40a1bb09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>T Barden</td>\n",
              "      <td>2022-08-08</td>\n",
              "      <td>✅ Trip Verified |  Emirates not to blame, but ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>D Sharish</td>\n",
              "      <td>2018-02-25</td>\n",
              "      <td>✅ Trip Verified |  The crew on Emirates are su...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>H Madasan</td>\n",
              "      <td>2024-07-04</td>\n",
              "      <td>✅ Trip Verified |  I have always been flying i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102</th>\n",
              "      <td>Rachelle Saker</td>\n",
              "      <td>2017-11-08</td>\n",
              "      <td>✅ Verified Review |  Barcelona to Melbourne vi...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>Allan Gathercoal</td>\n",
              "      <td>2018-11-04</td>\n",
              "      <td>✅ Trip Verified |  Seattle to Dubai. This was ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Name Date Published  \\\n",
              "307           T Barden     2022-08-08   \n",
              "993          D Sharish     2018-02-25   \n",
              "85           H Madasan     2024-07-04   \n",
              "1102    Rachelle Saker     2017-11-08   \n",
              "822   Allan Gathercoal     2018-11-04   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "307   ✅ Trip Verified |  Emirates not to blame, but ...      9  \n",
              "993   ✅ Trip Verified |  The crew on Emirates are su...      8  \n",
              "85    ✅ Trip Verified |  I have always been flying i...      3  \n",
              "1102  ✅ Verified Review |  Barcelona to Melbourne vi...      4  \n",
              "822   ✅ Trip Verified |  Seattle to Dubai. This was ...      5  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emirates_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccCNXlTm7mw",
        "outputId": "ddac4cae-2c63-48bd-8fc2-256c6dd5b778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2464, 4)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emirates_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EsysrJm-_M"
      },
      "source": [
        "#5.ANA All Nippon Airways"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RJ6d3EuFnFMg"
      },
      "outputs": [],
      "source": [
        "def scrape_page_ANA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/ana-all-nippon-airways/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KgCU31snNaA",
        "outputId": "cc115d47-b643-4cee-f990-c0829ff6c367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "ANA_reviews = []\n",
        "total_pages = 62\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_ANA(page_number)\n",
        "    ANA_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "n2QcSkg-naGj"
      },
      "outputs": [],
      "source": [
        "ANA_reviews_df = pd.DataFrame(ANA_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "lk9_YTSSny-G",
        "outputId": "1b20ed61-4a3c-48bb-f70f-d888ed89b174"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>Suryaputra Wijaksana</td>\n",
              "      <td>2018-07-30</td>\n",
              "      <td>Not Verified |  Jakarta to Tokyo Haneda. This ...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>H Tennant</td>\n",
              "      <td>2016-11-15</td>\n",
              "      <td>✅ Verified Review | Tokyo Haneda to Osaka Itam...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>A Kirk</td>\n",
              "      <td>2019-10-30</td>\n",
              "      <td>✅ Trip Verified |  I had a domestic flight fro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>B Duston</td>\n",
              "      <td>2014-01-28</td>\n",
              "      <td>Recently took a flight from Bangkok-Tokyo-JFK....</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>Larry Kopp</td>\n",
              "      <td>2016-03-14</td>\n",
              "      <td>We flew ANA from Chicago to Singapore via Toky...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Name Date Published  \\\n",
              "173  Suryaputra Wijaksana     2018-07-30   \n",
              "278             H Tennant     2016-11-15   \n",
              "121                A Kirk     2019-10-30   \n",
              "453              B Duston     2014-01-28   \n",
              "305            Larry Kopp     2016-03-14   \n",
              "\n",
              "                                          Text Content Rating  \n",
              "173  Not Verified |  Jakarta to Tokyo Haneda. This ...      8  \n",
              "278  ✅ Verified Review | Tokyo Haneda to Osaka Itam...     10  \n",
              "121  ✅ Trip Verified |  I had a domestic flight fro...      1  \n",
              "453  Recently took a flight from Bangkok-Tokyo-JFK....     10  \n",
              "305  We flew ANA from Chicago to Singapore via Toky...     10  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANA_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtM_sBhn1Kf",
        "outputId": "03faef89-8ada-42fb-dfd6-e3ed54bdfcff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(620, 4)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANA_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDr4aW8an5CZ"
      },
      "source": [
        "#6. Turkish Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "X-RbwaSJn-wN"
      },
      "outputs": [],
      "source": [
        "def scrape_page_Turk(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/turkish-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qytC_yfqoYDF",
        "outputId": "52ef200d-e2d0-4ee2-d7e0-f9727aa4cb66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n",
            "150 pages extraction completed\n",
            "160 pages extraction completed\n",
            "170 pages extraction completed\n",
            "180 pages extraction completed\n",
            "190 pages extraction completed\n",
            "200 pages extraction completed\n",
            "210 pages extraction completed\n",
            "220 pages extraction completed\n",
            "230 pages extraction completed\n",
            "240 pages extraction completed\n",
            "250 pages extraction completed\n",
            "260 pages extraction completed\n",
            "270 pages extraction completed\n",
            "280 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "turkish_airlines_reviews = []\n",
        "total_pages = 280\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_Turk(page_number)\n",
        "    turkish_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "azbkUuDvpZ1i"
      },
      "outputs": [],
      "source": [
        "turkish_airlines_reviews_df = pd.DataFrame(turkish_airlines_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "bJfb11e2pbOI",
        "outputId": "401d274e-58fc-4a85-af41-67d69cf3109f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>Charel Trierweiler</td>\n",
              "      <td>2023-09-02</td>\n",
              "      <td>✅ Trip Verified |  Incompetent and disrespectf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Ralf Kollmann</td>\n",
              "      <td>2023-10-27</td>\n",
              "      <td>Not Verified |  I cannot understand all compla...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>P Shayaran</td>\n",
              "      <td>2022-10-05</td>\n",
              "      <td>✅ Trip Verified |  My flight was scheduled on ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>950</th>\n",
              "      <td>E Marroul</td>\n",
              "      <td>2021-02-06</td>\n",
              "      <td>✅ Trip Verified |  I'm a frequent traveler wit...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1315</th>\n",
              "      <td>M Shaw</td>\n",
              "      <td>2019-05-05</td>\n",
              "      <td>✅ Trip Verified | Istanbul to Budapest via Dub...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Name Date Published  \\\n",
              "428   Charel Trierweiler     2023-09-02   \n",
              "368        Ralf Kollmann     2023-10-27   \n",
              "576           P Shayaran     2022-10-05   \n",
              "950            E Marroul     2021-02-06   \n",
              "1315              M Shaw     2019-05-05   \n",
              "\n",
              "                                           Text Content Rating  \n",
              "428   ✅ Trip Verified |  Incompetent and disrespectf...      1  \n",
              "368   Not Verified |  I cannot understand all compla...     10  \n",
              "576   ✅ Trip Verified |  My flight was scheduled on ...      1  \n",
              "950   ✅ Trip Verified |  I'm a frequent traveler wit...      2  \n",
              "1315  ✅ Trip Verified | Istanbul to Budapest via Dub...      2  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turkish_airlines_reviews_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVPkCPfopc1m",
        "outputId": "508f0749-61c6-4c71-a81f-92ecdd98803a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2800, 4)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turkish_airlines_reviews_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#7. Korean Air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_KA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/korean-air/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "korean_air_reviews = []\n",
        "total_pages = 60\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_KA(page_number)\n",
        "    korean_air_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "korean_air_reviews_df = pd.DataFrame(korean_air_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#8. Air France"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_AF(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/air-france/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n",
            "50 pages extraction completed\n",
            "60 pages extraction completed\n",
            "70 pages extraction completed\n",
            "80 pages extraction completed\n",
            "90 pages extraction completed\n",
            "100 pages extraction completed\n",
            "110 pages extraction completed\n",
            "120 pages extraction completed\n",
            "130 pages extraction completed\n",
            "140 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "air_france_reviews = []\n",
        "total_pages = 146\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_AF(page_number)\n",
        "    air_france_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "air_france_reviews_df = pd.DataFrame(air_france_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#9. Japan Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_JA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/japan-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "japan_airlines_reviews = []\n",
        "total_pages = 44\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_JA(page_number)\n",
        "    japan_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "japan_airlines_reviews_df = pd.DataFrame(japan_airlines_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#10. Hainan Airlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scrape_page_HA(page_number):\n",
        "    url = f'https://www.airlinequality.com/airline-reviews/hainan-airlines/page/{page_number}/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    for review_block in soup.find_all('article', itemprop='review'):  # use the full review container\n",
        "        name_tag = review_block.find('span', itemprop='name')\n",
        "        date_tag = review_block.find('time', itemprop='datePublished')\n",
        "        text_content_div = review_block.find('div', class_='text_content')\n",
        "        rating_tag = review_block.find('span', itemprop='ratingValue')\n",
        "\n",
        "        # Extract review details with error handling\n",
        "        name = name_tag.text.strip() if name_tag else 'N/A'\n",
        "        date_published = date_tag['datetime'] if date_tag else 'N/A'\n",
        "        text_content = text_content_div.text.strip() if text_content_div else 'N/A'\n",
        "        rating = rating_tag.get_text(strip=True) if rating_tag else 'N/A'\n",
        "\n",
        "        # Append extracted data to the list\n",
        "        reviews.append({\n",
        "            'Name': name,\n",
        "            'Date Published': date_published,\n",
        "            'Text Content': text_content,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 pages extraction completed\n",
            "20 pages extraction completed\n",
            "30 pages extraction completed\n",
            "40 pages extraction completed\n"
          ]
        }
      ],
      "source": [
        "hainan_airlines_reviews = []\n",
        "total_pages = 43\n",
        "for page_number in range(1, total_pages + 1):\n",
        "    page_reviews = scrape_page_HA(page_number)\n",
        "    hainan_airlines_reviews.extend(page_reviews)\n",
        "\n",
        "    # Print progress message\n",
        "    if page_number % 10 == 0:\n",
        "        print(f\"{page_number} pages extraction completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "hainan_airlines_reviews_df = pd.DataFrame(hainan_airlines_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining Datasets together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "uHiVTVI3rTKe"
      },
      "outputs": [],
      "source": [
        "qatar_airways_reviews_df.insert(0, 'Airlines', 'qatar_airways')\n",
        "singapore_airlines_reviews_df.insert(0, 'Airlines', 'singapore_airlines')\n",
        "cathay_pacific_airways_reviews_df.insert(0, 'Airlines', 'cathay_pacific_airlines')\n",
        "emirates_reviews_df.insert(0, 'Airlines', 'emirates')\n",
        "ANA_reviews_df.insert(0, 'Airlines', 'all_nippon_airways')\n",
        "turkish_airlines_reviews_df.insert(0, 'Airlines', 'turkish_airlines')\n",
        "korean_air_reviews_df.insert(0, 'Airlines', 'korean_air')\n",
        "air_france_reviews_df.insert(0, 'Airlines', 'air_france')\n",
        "japan_airlines_reviews_df.insert(0, 'Airlines', 'japan_airlines')\n",
        "hainan_airlines_reviews_df.insert(0, 'Airlines', 'hainan_airlines')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "uOPCjB3rriRa"
      },
      "outputs": [],
      "source": [
        "airlines_review = pd.concat([\n",
        "    qatar_airways_reviews_df,\n",
        "    singapore_airlines_reviews_df,\n",
        "    cathay_pacific_airways_reviews_df,\n",
        "    emirates_reviews_df,\n",
        "    ANA_reviews_df,\n",
        "    turkish_airlines_reviews_df,\n",
        "    korean_air_reviews_df,\n",
        "    air_france_reviews_df,\n",
        "    japan_airlines_reviews_df,\n",
        "    hainan_airlines_reviews_df\n",
        "], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VcJufYJCsC3x",
        "outputId": "b4b69043-d76e-4268-cb64-414a697c0379"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Airlines</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Text Content</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10706</th>\n",
              "      <td>turkish_airlines</td>\n",
              "      <td>R Allam</td>\n",
              "      <td>2017-04-25</td>\n",
              "      <td>✅ Verified Review | Istanbul to Izmir with Tur...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1589</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>E Walynsk</td>\n",
              "      <td>2017-08-16</td>\n",
              "      <td>✅ Verified Review |  Auckland to Warsaw via Do...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11068</th>\n",
              "      <td>turkish_airlines</td>\n",
              "      <td>Pierre Hamblenne</td>\n",
              "      <td>2015-12-11</td>\n",
              "      <td>This was a Turkish Airlines connection flight ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10641</th>\n",
              "      <td>turkish_airlines</td>\n",
              "      <td>Anders Pedersen</td>\n",
              "      <td>2017-09-07</td>\n",
              "      <td>✅ Verified Review |  Hong Kong - Istanbul - Co...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>Francesco Leonardi</td>\n",
              "      <td>2024-01-05</td>\n",
              "      <td>✅ Trip Verified |  I booked a round-trip fligh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6608</th>\n",
              "      <td>emirates</td>\n",
              "      <td>Andrea Spindel</td>\n",
              "      <td>2018-12-19</td>\n",
              "      <td>✅ Trip Verified |  Brisbane to Nairobi via Dub...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1564</th>\n",
              "      <td>qatar_airways</td>\n",
              "      <td>Anders Pedersen</td>\n",
              "      <td>2017-10-03</td>\n",
              "      <td>✅ Verified Review |  Copenhagen to Ho Chi Minh...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10124</th>\n",
              "      <td>turkish_airlines</td>\n",
              "      <td>Ed Harding</td>\n",
              "      <td>2019-09-05</td>\n",
              "      <td>✅ Trip Verified | Konya to London via Istanbul...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13671</th>\n",
              "      <td>air_france</td>\n",
              "      <td>Marilyn Suttle</td>\n",
              "      <td>2013-10-25</td>\n",
              "      <td>Flew LAX to Paris and on to Athens and back th...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4151</th>\n",
              "      <td>singapore_airlines</td>\n",
              "      <td>Casper Yap</td>\n",
              "      <td>2014-02-05</td>\n",
              "      <td>HKG-SIN-KUL. Older plane a bit dirty. IFE on t...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Airlines                Name Date Published  \\\n",
              "10706    turkish_airlines             R Allam     2017-04-25   \n",
              "1589        qatar_airways           E Walynsk     2017-08-16   \n",
              "11068    turkish_airlines    Pierre Hamblenne     2015-12-11   \n",
              "10641    turkish_airlines     Anders Pedersen     2017-09-07   \n",
              "298         qatar_airways  Francesco Leonardi     2024-01-05   \n",
              "6608             emirates      Andrea Spindel     2018-12-19   \n",
              "1564        qatar_airways     Anders Pedersen     2017-10-03   \n",
              "10124    turkish_airlines          Ed Harding     2019-09-05   \n",
              "13671          air_france      Marilyn Suttle     2013-10-25   \n",
              "4151   singapore_airlines          Casper Yap     2014-02-05   \n",
              "\n",
              "                                            Text Content Rating  \n",
              "10706  ✅ Verified Review | Istanbul to Izmir with Tur...     10  \n",
              "1589   ✅ Verified Review |  Auckland to Warsaw via Do...      5  \n",
              "11068  This was a Turkish Airlines connection flight ...      1  \n",
              "10641  ✅ Verified Review |  Hong Kong - Istanbul - Co...      8  \n",
              "298    ✅ Trip Verified |  I booked a round-trip fligh...      1  \n",
              "6608   ✅ Trip Verified |  Brisbane to Nairobi via Dub...      4  \n",
              "1564   ✅ Verified Review |  Copenhagen to Ho Chi Minh...      8  \n",
              "10124  ✅ Trip Verified | Konya to London via Istanbul...      3  \n",
              "13671  Flew LAX to Paris and on to Athens and back th...      8  \n",
              "4151   HKG-SIN-KUL. Older plane a bit dirty. IFE on t...      6  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airlines_review.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lwqQtCzsFjJ",
        "outputId": "4dc577a6-fa92-4b94-e868-3bf249f9f91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14602, 5)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airlines_review.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "_sYBW_lnsOAA"
      },
      "outputs": [],
      "source": [
        "airlines_review.to_csv('airlines_review.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
